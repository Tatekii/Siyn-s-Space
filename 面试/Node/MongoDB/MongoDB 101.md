## MongoDB 基础概念

### **文档（Document）**
MongoDB 的核心数据单元，相当于关系型数据库中的“行”。文档是 `BSON（Binary JSON）`格式的键值对集合，具有高度灵活性，可以包含嵌套的文档和数组。
    
```js
{ name: "Alice", age: 30, city: "New York", interests: ["coding", "hiking"] }
```
        
### **集合（Collection）**
相当于关系型数据库中的“表”。集合是文档的组，可以包含多个文档。与关系型数据库不同，集合中的文档不强制要求拥有相同的结构（这体现了其**无模式（Schema-less）**的特性）。
    
### **数据库（Database）**
一个 MongoDB 实例可以包含多个数据库，每个数据库包含独立的集合。
    
### **\_id 字段**
每个 MongoDB 文档在插入时都会自动生成一个唯一的 `_id` 字段，作为其主键。如果插入文档时没有指定 `_id`，MongoDB 会自动生成一个 `ObjectId` 类型的值。
    
### **内嵌文档与数组**
MongoDB 允许在文档中嵌入其他文档或数组，这使得复杂的数据结构可以存储在一个独立的文档中，减少了传统关系型数据库中多表 JOIN 的需求。
    
```json
{
	"order_id": 123,
	"customer": { "name": "Bob", "email": "bob@example.com" },
	"items": [
		{ "product_id": 1, "name": "Laptop", "qty": 1, "price": 1200 },
        { "product_id": 2, "name": "Mouse", "qty": 1, "price": 25 }
	],
	"total_amount": 1225
}
```

## MongoDB Shell 操作
掌握 MongoDB Shell 是与数据库交互的基础。

- **连接数据库**：
    
    - `mongo`：连接到默认的 `test` 数据库。
        
    - `mongo --port 27018`：连接到指定端口。
        
- **显示数据库**：`show dbs`
    
- **切换/创建数据库**：`use mydatabase` (如果数据库不存在，会自动创建)
    
- **显示集合**：`show collections`
    
- **插入文档**：
    
    - `db.collection.insertOne({ name: "Doc A" })`
        
    - `db.collection.insertMany([{ name: "Doc B" }, { name: "Doc C" }])`
        
- **查询文档**：
    
    - `db.collection.find()`：查询所有文档。
        
    - `db.collection.find({ name: "Doc A" })`：按条件查询。
        
    - `db.collection.findOne({ age: { $gt: 25 } })`：查询单个文档，`$gt` 是大于操作符。
        
    - **投影**：`db.collection.find({}, { name: 1, age: 1, _id: 0 })`：只返回 `name` 和 `age` 字段，不返回 `_id`。
        
- **更新文档**：
    
    - `db.collection.updateOne({ name: "Doc A" }, { $set: { age: 30 } })`：更新匹配到的第一个文档。
        
    - `db.collection.updateMany({ age: { $lt: 30 } }, { $inc: { age: 1 } })`：更新所有匹配的文档，`$inc` 是递增操作符。
        
- **删除文档**：
    
    - `db.collection.deleteOne({ name: "Doc A" })`
        
    - `db.collection.deleteMany({ age: { $gt: 50 } })`
        
- **删除集合**：`db.collection.drop()`
    
- **删除数据库**：`db.dropDatabase()`


## 索引（Indexes）

索引对于 MongoDB 的查询性能至关重要，与关系型数据库中的索引概念类似。

### **创建索引**
```js
db.collection.createIndex({ field_name: 1 })` (1 表示升序，-1 表示降序)。
```
    
### **复合索引**
```js
db.collection.createIndex({ field1: 1, field2: -1 })
```

    
### **唯一索引**
```js
db.collection.createIndex({ email: 1 }, { unique: true })`，确保 `email` 字段的值唯一。
```
    
### **稀疏索引（Sparse Indexes）**
只为存在索引字段的文档创建索引。
```js
db.users.createIndex( { email: 1 }, { unique: true, sparse: true } )
```
在这个例子中：
- 如果一个文档是 `{ _id: 1, name: "Alice", email: "alice@example.com" }`，它会包含在索引中。
- 如果一个文档是 `{ _id: 2, name: "Bob", email: "bob@example.com" }`，它会包含在索引中。
- 如果一个文档是 `{ _id: 3, name: "Charlie" }`（没有 `email` 字段），它**不会**包含在索引中。
- 现在，你可以插入两个 `email` 字段都为空或不存在的文档，而不会违反唯一性约束，例如：
    - `db.users.insertOne({ name: "David" })`
    - `db.users.insertOne({ name: "Eve" })`
    - 但你不能插入两个 `email` 都是 `"frank@example.com"` 的文档。

### **TTL 索引（Time-To-Live Indexes）**
**TTL（Time-To-Live）索引**是一种特殊的单字段索引，MongoDB 利用它来**自动删除**超过一定“寿命”的文档。这在处理时效性数据（如日志、会话、缓存）时非常有用。

TTL 索引基于日期类型的字段，MongoDB 会定期检查该字段的值，并删除那些值早于当前时间加上一个指定存活时间的文档。

示例：
```js
db.log_entries.createIndex( { "createdAt": 1 }, { expireAfterSeconds: 86400 } // 24小时 = 86400秒 )
```
在这个例子中：

- `createdAt` 必须是一个 **日期类型**（Date）的字段。
- 当一个文档插入后，MongoDB 会查看 `createdAt` 字段的值。
- 在 `createdAt` 值的基础上加上 86400 秒后，如果当前时间超过了这个计算出来的时间点，该文档就会被 MongoDB 的后台 TTL 清理进程自动删除。
    
#### TTL 索引的工作机制

- **后台进程**：MongoDB 有一个专门的后台进程会定期（默认为 60 秒一次）运行，扫描包含 TTL 索引的集合。
    
- **删除策略**：当进程发现某个文档的过期时间已到，就会将其从集合中删除。删除操作类似于常规的删除，但由数据库自动触发。
    
- **单字段限制**：TTL 索引只能定义在**单个字段**上。
    
- **复合索引不能是 TTL 索引**：你不能在一个复合索引上指定 `expireAfterSeconds`。
    
- **字段类型**：被索引的字段必须是 **BSON 日期类型**。如果该字段是数组，MongoDB 会使用数组中最小的（最老的）日期来计算过期时间。如果字段不存在或不是日期类型，文档不会被删除。

#### 注意事项：

- TTL 索引只删除**整个文档**，不能删除文档中的某个字段。
    
- 删除操作是异步的，所以文档在过期后可能不会立即被删除。这通常是分钟级到秒级的延迟。
    
- TTL 索引不能用于复制集的主节点之外的节点，从节点会复制主节点的删除操作。

### ⏱️**分析查询**
使用 `db.collection.explain().find(...)` 可以查看查询的执行计划，了解是否使用了索引以及查询效率。
    
## 聚合框架（Aggregation Framework）

MongoDB 的聚合框架是一个强大的工具，用于对文档进行数据处理和分析，类似于 SQL 中的 `GROUP BY`、`JOIN`、`SUM` 等操作。它通过管道（Pipeline）的形式工作，每个阶段对输入文档执行特定的操作，然后将结果传递给下一个阶段。

### **常用管道阶段**：

#### `$match`
过滤文档（相当于 `WHERE`）。
```js
db.orders.aggregate([ { $match: { status: "completed", amount: { $gt: 100 } } } ])
```
####  `$project`
选择、重命名或添加/删除字段（相当于SELECT）。
```js
db.users.aggregate([ { $project: { _id: 0, 
// 不显示 _id 字段 
fullName: { $concat: ["$firstName", " ", "$lastName"] }, // 合并字段 email: 1 // 显示 email 字段 } } ])
```

#### `$group`
对文档进行分组，并执行聚合计算（如 `$sum`, `$avg`, `$min`, `$max`）。
**类比 SQL**：`GROUP BY` 子句，以及 `SUM()`, `COUNT()`, `AVG()` 等聚合函数。
```js
db.products.aggregate([ 
	{ $group: { 
		_id: "$category", // 按 category 字段分组 
		totalProducts: { $sum: 1 }, // 计算每个分类的产品数
		averagePrice: { $avg: "$price" } // 计算每个分类的平均价格 
		} 
	} 
])
```

#### `$sort`
对结果进行排序。
**类比 SQL**：`ORDER BY` 子句。
```js
db.employees.aggregate([ { $sort: { salary: -1, name: 1 } } // 先按薪水降序，再按姓名升序 ])
```

#### `$limit`
限制返回的文档数量。
        
#### `$skip`
跳过指定数量的文档。

#### `$unwind`
将文档中的数组字段“解构”，为数组中的每个元素生成一个新文档。
```js
// 原始文档: 
{ _id: 1, name: "Product A", tags: ["电子", "家居"] } 

db.products.aggregate([ { $unwind: "$tags" } ]) 
// 结果示例: 
{ _id: 1, name: "Product A", tags: "电子" } 
{ _id: 1, name: "Product A", tags: "家居" }
```
#### `$lookup`
执行左外连接（left outer join）操作，将来自另一个集合的文档添加到结果中（MongoDB 4.0 引入，部分弥补了无 JOIN 的劣势）。
```js
// 假设有 orders 集合和 products 集合 
db.orders.aggregate([ 
	{ $lookup: { 
		from: "products", // 要连接的集合 
		localField: "productId", // orders 集合中的字段 
		foreignField: "_id", // products 集合中的字段 
		as: "productInfo" // 结果中添加的新字段名，包含匹配的 products 文档} 
	} 
])
```
### **示例**：计算每个用户的订单总金额
    
```js
db.orders.aggregate([
	{ $match: { status: "completed" } }, // 过滤已完成订单
	{ $group: {
		_id: "$customer_id", // 按 customer_id 分组
		total_spent: { $sum: "$total_amount" }, // 计算总金额
		order_count: { $sum: 1 } // 计算订单数量
	}},
	{ $sort: { total_spent: -1 } }, // 按总金额降序排序
	{ $limit: 10 } // 只返回前10名
])
```

### 性能考虑
- **尽早过滤**：将 `$match` 阶段放在聚合管道的前面，可以减少后续阶段处理的文档数量。

- **索引利用[`$match`](#`$match`) 和 [`$sort`](#`$sort`) 阶段可以利用索引来加速操作。
    
- **内存限制**：聚合操作在处理大量数据时可能会消耗大量内存。如果操作超出内存限制（通常是 100MB），MongoDB 会报错。你可以通过设置 `allowDiskUse: true` 选项来允许聚合操作使用磁盘进行处理，但性能会下降。
    
- **避免全表扫描**：设计聚合管道时尽量利用索引。
## 💿复制集（Replica Sets）
**复制集（Replica Set）** 是 MongoDB 提高数据**高可用性（High Availability）**和**数据冗余（Data Redundancy）**的核心机制。它由一组 MongoDB 实例组成，这些实例维护着相同的数据集，确保即使某个实例发生故障，数据服务也能持续可用。
### **主节点（Primary）**
- **写入操作的唯一入口：** 复制集中所有的**写入操作**（插入、更新、删除）都必须通过主节点进行。
    
- **读取操作的默认目标：** 默认情况下，读取操作也会发送到主节点，但客户端也可以配置将读取分发到从节点。
    
- **日志记录：** 主节点会将所有的写入操作记录到一个特殊的日志文件——**操作日志（Oplog）**中。这个 Oplog 是从节点同步数据的基础。
    
- **高可用性的关键：** 当主节点发生故障时，复制集中的其他成员会通过选举（Election）过程，推选出一个新的主节点，从而实现自动故障转移（Automatic Failover）。
    
### **从节点（Secondary）**
- **数据复制者：** 从节点通过异步地读取主节点的 Oplog，并将其应用到自己的数据集中，从而保持与主节点的数据同步。
    
- **读操作的潜在目标：** 从节点可以配置为处理读取操作，从而分担主节点的读取压力，实现**读写分离**。
    
- **参与选举：** 当主节点下线时，从节点会参与选举新的主节点。
    
- **数据冗余：** 它们提供了数据副本，即使主节点数据丢失，从节点也能提供数据备份。
### **仲裁节点（Arbiter）**

- **不存储数据：** 仲裁节点是一个特殊的复制集成员，它**不存储数据副本**，因此不需要大量的磁盘空间。
    
- **只参与选举：** 仲裁节点的主要作用是参与主节点的选举过程。当复制集成员数量为偶数时，或者需要一个轻量级节点来帮助达到多数派投票条件时，可以使用仲裁节点。
    
- **避免脑裂：** 在网络分区或成员数量为偶数的情况下，仲裁节点有助于复制集成员形成明确的多数派，从而避免“脑裂”（Split-Brain）问题——即多个主节点同时存在的情况。
    
- **推荐用于非数据节点：** 通常不建议在包含偶数数据节点的复制集中使用仲裁节点，而是建议拥有奇数个数据节点。
### **选举机制**
当主节点出现故障时，复制集中的从节点会通过选举选出一个新的主节点，从而保证服务的高可用性。
    
### **读写分离**
可以将读请求分发到从节点，减轻主节点压力，提高读取性能。
#### 读偏好
 1. `primary` (默认)
	- **功能：** 所有的读取操作都只会发送到复制集中的**主节点**。
	
	- **优点：** 保证**强一致性（Strong Consistency）**，因为所有写入操作都发生在主节点，所以读取到的数据永远是最新的。
    
	- **缺点：** 无法实现读写分离，主节点压力大，不适合读密集型工作负载。
    
	- **适用场景：** 对数据一致性要求极高，不能容忍任何延迟的应用，如金融交易。
    

 2. `primaryPreferred`

	- **功能：** 优先从主节点读取。如果主节点不可用（如发生故障转移），则会从可用的从节点读取。
    
	- **优点：** 在主节点正常时提供强一致性，在主节点故障时提供高可用性。
    
	- **缺点：** 切换到从节点读取时，可能会遇到**最终一致性**问题（因为从节点的数据可能有短暂延迟）。
    
	- **适用场景：** 大多数通用应用，既希望获得主节点的最新数据，又希望在主节点故障时保持服务可用。
    

 3. `secondary`

	- **功能：** 所有的读取操作都只会发送到复制集中的**从节点**。
    
	- **优点：** 实现真正的读写分离，显著降低主节点的负载，提高整体吞吐量。
    
	- **缺点：** 只能保证**最终一致性**。由于从节点异步复制数据，读取到的数据可能不是最新的（存在复制延迟）。如果从节点都不可用，读取操作将失败。
    
	- **适用场景：** 读密集型应用，对数据最新程度要求不高，能容忍一定数据延迟的场景，如日志分析、排行榜、内容展示（非关键信息）。
    

 4. `secondaryPreferred`

	- **功能：** 优先从从节点读取。如果没有可用的从节点，则会从主节点读取。
    
	- **优点：** 实现了读写分离，同时在没有从节点可用时提供了回退机制，确保服务可用。
    
	- **缺点：** 同样面临最终一致性问题。
    
	- **适用场景：** 与 `secondary` 类似，但更强调可用性，即使牺牲一些读写分离的优势也要确保读取服务不中断。
    

 5. `nearest`

	- **功能：** 从网络延迟最低的节点读取（无论是主节点还是从节点）。驱动程序会测量与每个复制集成员的延迟，并选择延迟最小的节点。
    
	- **优点：** 最小化读取延迟，适用于分布式部署，客户端可能离不同的数据中心更近的情况。
    
	- **缺点：** 无法保证数据一致性（可能从延迟最低的从节点读取到旧数据），也无法保证读写分离。
    
	- **适用场景：** 对读操作响应时间要求极高，且数据一致性要求不那么严格的跨区域部署。
#### 指定读偏好
1. 在连接复制集时指定读偏好
```js
const client = new MongoClient(uri, { 
	// 设置读偏好为 secondaryPreferred 
	readPreference: 'secondaryPreferred' }
);
```
1. 查询级别配置（覆盖默认值）
```js
// 这个查询将强制从主节点读取 
const primaryDoc = await collection.find({ status: "critical" }, { readPreference: 'primary' }).toArray(); console.log("Docs from primary (forced):", primaryDoc); 
// 这个查询将强制从从节点读取 
const secondaryDoc = await collection.find({ category: "logs" }, { readPreference: 'secondary' }).toArray(); console.log("Docs from secondary (forced):", secondaryDoc);
```
    
### **搭建**
通常需要至少 3 个节点（一个主节点，两个从节点）来实现多数派选举，保证数据一致性。
## 🃏分片（Sharding）

分片（Sharding）**是 MongoDB 实现**水平扩展（Horizontal Scaling / Scale Out）的核心机制。当单个 MongoDB 实例（或一个复制集）无法满足存储容量、读写吞吐量或并发连接的性能要求时，分片就成为了解决方案。它通过将数据分散存储到多个独立的 MongoDB 实例（称为分片）上，从而实现了大规模数据的存储和处理。
### **分片键（Shard Key）**
**分片键**是决定数据如何分布在各个分片上的核心。它是一个或多个文档字段的索引。选择一个好的分片键至关重要，因为它直接影响集群的性能和可扩展性。
#### **分片键的选择原则**

1. **基数（Cardinality）高**
	分片键的值应该足够多样化，以确保数据能够均匀地分布到所有的分片上，避免**热点（Hotspot）**。
    
    - **坏例子：** `gender` 字段（只有“男”/“女”）作为分片键，会导致数据只集中在两个分片。
        
2. **频率（Frequency）均匀**
	不同的分片键值应该被查询或更新的频率大致相同，避免某些分片上的数据被频繁访问，而其他分片空闲。
    
3. **写入分散性（Write Distribution）** 
	对于写入密集型应用，分片键的连续值应该被路由到不同的分片，避免所有新写入集中到同一个分片（如使用时间戳作为分片键）。
    
4. **查询隔离性（Query Isolation）** 
	理想情况下，查询应该只访问一个分片（**定向查询 / Targeted Query**），而不是需要查询所有分片（**广播查询 / Scatter-Gather Query**），后者效率较低。

#### 分片键的类型
- **哈希分片（Hashed Sharding）** 
	对分片键的值进行哈希计算，然后根据哈希值将数据分布到分片上。
    
    - **优点：** 数据分布非常均匀，适用于插入操作分散的场景。
        
    - **缺点：** 不支持范围查询的定向（Targeted）路由，范围查询需要广播到所有分片。
        
    - **适用场景：** 需要均匀分布写入操作，且大部分查询是等值查询的场景。
        
- **范围分片（Ranged Sharding）**
	根据分片键的值范围将数据分布到不同的分片上。
    
    - **优点：** 支持高效的范围查询，可以定向到包含该范围数据的分片。
        
    - **缺点：** 如果分片键选择不当，可能导致数据分布不均匀（如使用时间戳，新数据都集中在最新的分片），形成热点。
        
    - **适用场景：** 经常进行范围查询，且能保证数据均匀分布的场景。
        
- **标签感知分片（Tag-Aware Sharding）** 
	允许你定义数据块的范围和标签，然后将这些标签关联到特定的分片。这可以用于将特定数据强制存储在指定分片上（例如，将特定地区的用户数据存储在对应数据中心的分片）。

### **分片集群组件**    
####  **分片（Shard）**
- **存储实际数据：** 每个分片都是一个独立的 MongoDB 复制集，负责存储集群数据的一部分。
    
- **高可用性：** 由于每个分片本身就是一个复制集，因此它提供了数据的高可用性和冗余。
    
- **性能提升：** 每个分片处理其自己所存储的数据的读写请求，从而分散了整个集群的负载。
        
####  **mongos（查询路由器）**
- **应用程序的接口：** `mongos` 实例是应用程序与分片集群进行交互的唯一接口。应用程序不需要知道数据存储在哪个分片上，所有请求都通过 `mongos` 进行路由。
    
- **查询路由：** `mongos` 会根据查询的分片键（Shard Key）将读写请求路由到正确的或相关的分片上。
    
- **结果聚合：** 对于需要从多个分片获取数据的查询，`mongos` 会将查询广播到所有相关的分片，并聚合它们返回的结果，然后返回给客户端。
    
- **无状态：** `mongos` 本身是无状态的，这意味着你可以启动多个 `mongos` 实例来实现高可用性和负载均衡。
        
#### **Config Server（配置服务器）**
- **存储集群元数据：** 配置服务器存储了分片集群的所有元数据，包括：
        
	- **分片与数据范围的映射：** 哪些数据块（chunk）存储在哪个分片上。
            
	- **分片键定义：** 集合的分片键。
            
	- **所有分片的列表和状态。**
            
- **复制集部署：** 从 MongoDB 3.4 版本开始，配置服务器本身也是以**复制集**的形式部署的，以确保元数据的高可用性和一致性。通常需要 3 个或 5 个配置服务器成员来形成多数派。
        
#### **工作原理**
- **数据路由：** 当应用程序通过 `mongos` 发送一个读写请求时，`mongos` 会首先根据请求的**分片键**查询配置服务器，以确定数据应该存储在哪个分片上，或者从哪个分片读取。
    
- **数据存储：** `mongos` 将请求发送到目标分片。目标分片处理请求并将结果返回给 `mongos`。
    
- **结果返回：** `mongos` 将结果（如果需要，会进行聚合）返回给应用程序。
    
- **数据块（Chunks）：** 分片集群将集合中的数据划分为一系列连续的**数据块（Chunks）**，每个数据块代表分片键值范围的一部分。当某个分片上的数据块数量或大小达到阈值时，MongoDB 会自动进行**数据块迁移（Chunk Migration）**，将数据块从一个分片移动到另一个分片，以实现数据在各个分片上的均衡分布。
## 安全性

### **启用认证**
为 MongoDB 实例配置用户和角色，要求客户端在连接时进行认证。
    
### **最小权限原则**
为用户授予完成其工作所需的最小权限。
    
### **网络访问控制**
限制哪些 IP 地址可以连接到 MongoDB 实例。
    
### **数据加密**
考虑传输中的数据加密（TLS/SSL）和静态数据加密。

## 备份与恢复
了解如何备份和恢复 MongoDB 数据至关重要，以防数据丢失或损坏。

-  **mongodump/mongorestore**
	官方提供的命令行工具，用于备份和恢复整个数据库或集合。
- **文件系统快照**
	对数据库目录进行快照备份。
-  **MongoDB Cloud Manager / Ops Manager**
	提供更全面的自动化备份和恢复解决方案。